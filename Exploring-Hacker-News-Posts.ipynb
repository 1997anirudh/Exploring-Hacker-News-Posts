{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project2 \n",
    "Study to explore Hacker News Posts \n",
    "We have a dataset consisting of 7 columns namely:\n",
    "1. id\n",
    "2. title\n",
    "3. URL\n",
    "4. The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "5. The number of comments that were made on the post\n",
    "6. The username of the person who submitted the post\n",
    "7.  username of the person who submitted the post\n",
    "8. created_at: The date and time at which the post was submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "opened_file = open(\"hacker_news.csv\")\n",
    "from csv import reader\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "headers = hn[0]\n",
    "print(headers)\n",
    "print(\"\\n\")\n",
    "hn = hn[1:]\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created 3 separate lists. \n",
    "We have segregated them based on the title on 2 concitions if the title attribute starts wih\n",
    "\"ASK HN\" or \"SHOW KN\" and all the others slipped into the other list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = [ ]\n",
    "show_posts = [ ]\n",
    "other_posts = [ ]\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    \n",
    "    \n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have 3 separate lists for\n",
    "1. ask hn \n",
    "2. show hn \n",
    "3. all others \n",
    "In the next section we have studied which one between ask and show hn recieves more comments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24483\n",
      "14.038417431192661\n",
      "===========================================\n",
      "11988\n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for val in ask_posts:\n",
    "    com = val[4]\n",
    "    com = int(com)\n",
    "    total_ask_comments += com\n",
    "print(total_ask_comments)\n",
    "avg_ask_comments = total_ask_comments/ len(ask_posts)\n",
    "print(avg_ask_comments)\n",
    "print(\"===========================================\")\n",
    "total_show_comments = 0\n",
    "for val in show_posts:\n",
    "    com = val[4]\n",
    "    com = int(com)\n",
    "    total_show_comments += com\n",
    "print(total_show_comments)\n",
    "avg_show_comments = total_show_comments/ len(show_posts)\n",
    "print(avg_show_comments)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above analysis , it is clear that Ask posts reviews more comments and thus recieves more average comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{9: 251, 13: 1253, 10: 793, 14: 1416, 16: 1814, 23: 543, 12: 687, 17: 1146, 15: 4477, 21: 1745, 20: 1722, 2: 1381, 18: 1439, 3: 421, 5: 464, 19: 1188, 1: 683, 22: 479, 8: 492, 4: 337, 0: 447, 6: 397, 7: 267, 11: 641}\n",
      "{9: 45, 13: 85, 10: 59, 14: 107, 16: 108, 23: 68, 12: 73, 17: 100, 15: 116, 21: 109, 20: 80, 2: 58, 18: 109, 3: 54, 5: 46, 19: 110, 1: 60, 22: 71, 8: 48, 4: 47, 0: 55, 6: 44, 7: 34, 11: 58}\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = [ ]\n",
    "for vals in ask_posts:\n",
    "    created_at = vals[6]\n",
    "    com = int(vals[4])\n",
    "    new_list = list([created_at, com])\n",
    "    result_list.append(new_list)\n",
    "    \n",
    "counts_by_hour = { }\n",
    "comments_by_hour = { }\n",
    "date_format = \"%m/%d/%Y %H:%M\"\n",
    "for hr in result_list:\n",
    "    datetime_str = hr[0]\n",
    "    comments = int(hr[1])\n",
    "    k = dt.datetime.strptime(datetime_str,date_format)\n",
    "    hour = k.hour\n",
    "    if hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "    else:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "print(comments_by_hour)\n",
    "print(counts_by_hour)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 5.5777777777777775], [13, 14.741176470588234], [10, 13.440677966101696], [14, 13.233644859813085], [16, 16.796296296296298], [23, 7.985294117647059], [12, 9.41095890410959], [17, 11.46], [15, 38.5948275862069], [21, 16.009174311926607], [20, 21.525], [2, 23.810344827586206], [18, 13.20183486238532], [3, 7.796296296296297], [5, 10.08695652173913], [19, 10.8], [1, 11.383333333333333], [22, 6.746478873239437], [8, 10.25], [4, 7.170212765957447], [0, 8.127272727272727], [6, 9.022727272727273], [7, 7.852941176470588], [11, 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = [ ]\n",
    "for val in comments_by_hour:\n",
    "    avg_by_hour.append([val,comments_by_hour[val]/counts_by_hour[val]])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n",
      "13:00: 14.74 average comments per post\n",
      "10:00: 13.44 average comments per post\n",
      "14:00: 13.23 average comments per post\n",
      "18:00: 13.20 average comments per post\n",
      "17:00: 11.46 average comments per post\n",
      "01:00: 11.38 average comments per post\n",
      "11:00: 11.05 average comments per post\n",
      "19:00: 10.80 average comments per post\n",
      "08:00: 10.25 average comments per post\n",
      "05:00: 10.09 average comments per post\n",
      "12:00: 9.41 average comments per post\n",
      "06:00: 9.02 average comments per post\n",
      "00:00: 8.13 average comments per post\n",
      "23:00: 7.99 average comments per post\n",
      "07:00: 7.85 average comments per post\n",
      "03:00: 7.80 average comments per post\n",
      "04:00: 7.17 average comments per post\n",
      "22:00: 6.75 average comments per post\n",
      "09:00: 5.58 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = [ ]\n",
    "for row in avg_by_hour:\n",
    "    val1 = row[0]\n",
    "    val2 = row[1]\n",
    "    swap_avg_by_hour.append([val2,val1])\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "for val in sorted_swap:\n",
    "    va1 = val[0]\n",
    "    va2 = str(val[1])\n",
    "    datetime_val = dt.datetime.strptime(va2,\"%H\")\n",
    "    datetime_val = dt.datetime.strftime(datetime_val,\"%H:%M\")\n",
    "    output = \"{0}: {1:.2f} average comments per post\".format(datetime_val,va1)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time that we have above is EST which is 10 hours and 30 mins behind the timezome that I currently reside. \n",
    "**1:30** IST is the period with the highest audience engagement and **19:30** IST is the time with the least engagement. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
